{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "char(cnn)  \n",
    "filter = [10,10,10,10,10,10]  \n",
    "14k parameters, 20 hidden unit biGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "explanation (InputLayer)        (None, 270, 19)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           (None, 150, 19)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cnn_layer_1 (cnn_layer)         multiple             4470        explanation[0][0]                \n",
      "                                                                 question[0][0]                   \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 23, 19)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 23, 19)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 270, 60)      0           cnn_layer_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 150, 60)      0           cnn_layer_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 420, 60)      0           dropout_1[0][0]                  \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 23, 60)       0           cnn_layer_1[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 23, 60)       0           cnn_layer_1[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 40)           9720        concatenate_1[0][0]              \n",
      "                                                                 dropout_3[0][0]                  \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Cosine_similarity (Lambda)      (None, 1)            0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_1[2][0]            \n",
      "__________________________________________________________________________________________________\n",
      "loss (Lambda)                   (None, 1)            0           Cosine_similarity[0][0]          \n",
      "                                                                 Cosine_similarity[1][0]          \n",
      "==================================================================================================\n",
      "Total params: 14,190\n",
      "Trainable params: 14,190\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "                    char_embed_flag : cnn       \n",
      "                      cutoff_length : 150       \n",
      "                       dropout_rate : 0.5       \n",
      "                      embedding_dim : 15        \n",
      "                            fcounts : list with 6 elements\n",
      "                           rnn_type : GRU       \n",
      "                          threshold : 0.5       \n",
      "                    trainable_count : 14190     \n",
      "                              units : 20        \n",
      "                         units_char : 20        \n",
      "                  untrainable_count : 0         \n",
      "                   adapt_embeddings : 0         \n",
      "running iteration 1...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 43s 32ms/step - loss: 0.5030 - val_loss: 0.5033\n",
      "learning_rate: 0.00100\n",
      "train loss: 0.5002\n",
      "val loss: 0.5033\n",
      "test loss: 0.4992\n",
      "train,val,test accuracies: 0.24/0.22/0.28\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 39s 28ms/step - loss: 0.4980 - val_loss: 0.5026\n",
      "learning_rate: 0.00100\n",
      "train loss: 0.5000\n",
      "val loss: 0.5026\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.25/0.22/0.26\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 38s 28ms/step - loss: 0.4870 - val_loss: 0.5030\n",
      "learning_rate: 0.00099\n",
      "train loss: 0.4999\n",
      "val loss: 0.5030\n",
      "test loss: 0.4999\n",
      "train,val,test accuracies: 0.24/0.22/0.27\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 38s 28ms/step - loss: 0.4962 - val_loss: 0.5029\n",
      "learning_rate: 0.00099\n",
      "train loss: 0.4998\n",
      "val loss: 0.5029\n",
      "test loss: 0.4999\n",
      "train,val,test accuracies: 0.25/0.21/0.29\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 81s 59ms/step - loss: 0.4980 - val_loss: 0.5029\n",
      "learning_rate: 0.00099\n",
      "train loss: 0.4998\n",
      "val loss: 0.5029\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.23/0.23/0.28\n",
      "training/val losses: 0.498/0.503 ... time taken is 342.40s\n",
      "running iteration 2...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 46s 34ms/step - loss: 0.5145 - val_loss: 0.5020\n",
      "learning_rate: 0.00099\n",
      "train loss: 0.4998\n",
      "val loss: 0.5020\n",
      "test loss: 0.5002\n",
      "train,val,test accuracies: 0.23/0.22/0.29\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 61s 44ms/step - loss: 0.4968 - val_loss: 0.5017\n",
      "learning_rate: 0.00098\n",
      "train loss: 0.4997\n",
      "val loss: 0.5017\n",
      "test loss: 0.5001\n",
      "train,val,test accuracies: 0.25/0.21/0.30\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 74s 55ms/step - loss: 0.4915 - val_loss: 0.5023\n",
      "learning_rate: 0.00098\n",
      "train loss: 0.4995\n",
      "val loss: 0.5023\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.25/0.23/0.31\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 86s 63ms/step - loss: 0.4944 - val_loss: 0.5025\n",
      "learning_rate: 0.00098\n",
      "train loss: 0.4995\n",
      "val loss: 0.5025\n",
      "test loss: 0.4999\n",
      "train,val,test accuracies: 0.26/0.23/0.31\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 91s 67ms/step - loss: 0.4967 - val_loss: 0.5025\n",
      "learning_rate: 0.00098\n",
      "train loss: 0.4994\n",
      "val loss: 0.5025\n",
      "test loss: 0.4999\n",
      "train,val,test accuracies: 0.25/0.23/0.30\n",
      "training/val losses: 0.497/0.503 ... time taken is 539.46s\n",
      "running iteration 3...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 90s 66ms/step - loss: 0.5077 - val_loss: 0.5020\n",
      "learning_rate: 0.00098\n",
      "train loss: 0.4995\n",
      "val loss: 0.5020\n",
      "test loss: 0.4997\n",
      "train,val,test accuracies: 0.25/0.25/0.30\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 89s 65ms/step - loss: 0.5026 - val_loss: 0.5017\n",
      "learning_rate: 0.00097\n",
      "train loss: 0.4995\n",
      "val loss: 0.5017\n",
      "test loss: 0.4995\n",
      "train,val,test accuracies: 0.24/0.25/0.31\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.5012 - val_loss: 0.5017\n",
      "learning_rate: 0.00097\n",
      "train loss: 0.4994\n",
      "val loss: 0.5017\n",
      "test loss: 0.4995\n",
      "train,val,test accuracies: 0.26/0.24/0.31\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 90s 66ms/step - loss: 0.5032 - val_loss: 0.5015\n",
      "learning_rate: 0.00097\n",
      "train loss: 0.4995\n",
      "val loss: 0.5015\n",
      "test loss: 0.4996\n",
      "train,val,test accuracies: 0.25/0.23/0.30\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 91s 66ms/step - loss: 0.5049 - val_loss: 0.5012\n",
      "learning_rate: 0.00097\n",
      "train loss: 0.4996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 0.5012\n",
      "test loss: 0.4997\n",
      "train,val,test accuracies: 0.25/0.24/0.30\n",
      "training/val losses: 0.505/0.501 ... time taken is 624.26s\n",
      "running iteration 4...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 92s 67ms/step - loss: 0.5024 - val_loss: 0.5011\n",
      "learning_rate: 0.00097\n",
      "train loss: 0.4997\n",
      "val loss: 0.5011\n",
      "test loss: 0.4997\n",
      "train,val,test accuracies: 0.23/0.25/0.29\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4996 - val_loss: 0.5011\n",
      "learning_rate: 0.00096\n",
      "train loss: 0.4997\n",
      "val loss: 0.5011\n",
      "test loss: 0.4997\n",
      "train,val,test accuracies: 0.23/0.25/0.28\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 90s 66ms/step - loss: 0.5034 - val_loss: 0.5010\n",
      "learning_rate: 0.00096\n",
      "train loss: 0.4997\n",
      "val loss: 0.5010\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.25/0.25/0.29\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 92s 67ms/step - loss: 0.5059 - val_loss: 0.5009\n",
      "learning_rate: 0.00096\n",
      "train loss: 0.4997\n",
      "val loss: 0.5009\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.25/0.25/0.28\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 92s 68ms/step - loss: 0.4962 - val_loss: 0.5008\n",
      "learning_rate: 0.00096\n",
      "train loss: 0.4997\n",
      "val loss: 0.5008\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.23/0.26/0.27\n",
      "training/val losses: 0.496/0.501 ... time taken is 631.26s\n",
      "running iteration 5...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 89s 66ms/step - loss: 0.4954 - val_loss: 0.5008\n",
      "learning_rate: 0.00096\n",
      "train loss: 0.4997\n",
      "val loss: 0.5008\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.23/0.26/0.29\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 90s 66ms/step - loss: 0.5036 - val_loss: 0.5007\n",
      "learning_rate: 0.00095\n",
      "train loss: 0.4997\n",
      "val loss: 0.5007\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.23/0.26/0.27\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 92s 67ms/step - loss: 0.4996 - val_loss: 0.5007\n",
      "learning_rate: 0.00095\n",
      "train loss: 0.4997\n",
      "val loss: 0.5007\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.23/0.28/0.27\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 91s 67ms/step - loss: 0.4982 - val_loss: 0.5007\n",
      "learning_rate: 0.00095\n",
      "train loss: 0.4996\n",
      "val loss: 0.5007\n",
      "test loss: 0.4999\n",
      "train,val,test accuracies: 0.23/0.27/0.26\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 89s 66ms/step - loss: 0.5015 - val_loss: 0.5008\n",
      "learning_rate: 0.00095\n",
      "train loss: 0.4995\n",
      "val loss: 0.5008\n",
      "test loss: 0.4998\n",
      "train,val,test accuracies: 0.24/0.26/0.27\n",
      "training/val losses: 0.501/0.501 ... time taken is 636.94s\n",
      "running iteration 6...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 92s 67ms/step - loss: 0.4974 - val_loss: 0.5008\n",
      "learning_rate: 0.00095\n",
      "train loss: 0.4995\n",
      "val loss: 0.5008\n",
      "test loss: 0.4997\n",
      "train,val,test accuracies: 0.24/0.26/0.27\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 88s 65ms/step - loss: 0.4923 - val_loss: 0.5009\n",
      "learning_rate: 0.00094\n",
      "train loss: 0.4995\n",
      "val loss: 0.5009\n",
      "test loss: 0.4996\n",
      "train,val,test accuracies: 0.25/0.28/0.25\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 89s 66ms/step - loss: 0.5007 - val_loss: 0.5010\n",
      "learning_rate: 0.00094\n",
      "train loss: 0.4994\n",
      "val loss: 0.5010\n",
      "test loss: 0.4995\n",
      "train,val,test accuracies: 0.25/0.29/0.27\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 92s 67ms/step - loss: 0.4973 - val_loss: 0.5010\n",
      "learning_rate: 0.00094\n",
      "train loss: 0.4993\n",
      "val loss: 0.5010\n",
      "test loss: 0.4994\n",
      "train,val,test accuracies: 0.25/0.28/0.27\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 89s 65ms/step - loss: 0.5013 - val_loss: 0.5011\n",
      "learning_rate: 0.00094\n",
      "train loss: 0.4992\n",
      "val loss: 0.5011\n",
      "test loss: 0.4993\n",
      "train,val,test accuracies: 0.25/0.26/0.27\n",
      "training/val losses: 0.501/0.501 ... time taken is 630.26s\n",
      "running iteration 7...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 93s 68ms/step - loss: 0.5036 - val_loss: 0.5010\n",
      "learning_rate: 0.00094\n",
      "train loss: 0.4992\n",
      "val loss: 0.5010\n",
      "test loss: 0.4994\n",
      "train,val,test accuracies: 0.25/0.26/0.25\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 91s 67ms/step - loss: 0.5023 - val_loss: 0.5010\n",
      "learning_rate: 0.00093\n",
      "train loss: 0.4992\n",
      "val loss: 0.5010\n",
      "test loss: 0.4994\n",
      "train,val,test accuracies: 0.24/0.26/0.26\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 90s 66ms/step - loss: 0.4920 - val_loss: 0.5012\n",
      "learning_rate: 0.00093\n",
      "train loss: 0.4990\n",
      "val loss: 0.5012\n",
      "test loss: 0.4993\n",
      "train,val,test accuracies: 0.25/0.27/0.27\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 92s 68ms/step - loss: 0.4911 - val_loss: 0.5013\n",
      "learning_rate: 0.00093\n",
      "train loss: 0.4989\n",
      "val loss: 0.5013\n",
      "test loss: 0.4992\n",
      "train,val,test accuracies: 0.25/0.27/0.26\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 93s 68ms/step - loss: 0.4956 - val_loss: 0.5013\n",
      "learning_rate: 0.00093\n",
      "train loss: 0.4988\n",
      "val loss: 0.5013\n",
      "test loss: 0.4992\n",
      "train,val,test accuracies: 0.25/0.27/0.27\n",
      "training/val losses: 0.496/0.501 ... time taken is 642.14s\n",
      "running iteration 8...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 93s 68ms/step - loss: 0.4949 - val_loss: 0.5016\n",
      "learning_rate: 0.00093\n",
      "train loss: 0.4986\n",
      "val loss: 0.5016\n",
      "test loss: 0.4992\n",
      "train,val,test accuracies: 0.24/0.28/0.29\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 93s 68ms/step - loss: 0.4974 - val_loss: 0.5017\n",
      "learning_rate: 0.00092\n",
      "train loss: 0.4985\n",
      "val loss: 0.5017\n",
      "test loss: 0.4992\n",
      "train,val,test accuracies: 0.25/0.26/0.29\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 88s 64ms/step - loss: 0.4918 - val_loss: 0.5022\n",
      "learning_rate: 0.00092\n",
      "train loss: 0.4980\n",
      "val loss: 0.5022\n",
      "test loss: 0.4991\n",
      "train,val,test accuracies: 0.25/0.28/0.29\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 88s 64ms/step - loss: 0.4872 - val_loss: 0.5028\n",
      "learning_rate: 0.00092\n",
      "train loss: 0.4972\n",
      "val loss: 0.5028\n",
      "test loss: 0.4984\n",
      "train,val,test accuracies: 0.27/0.27/0.29\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 89s 65ms/step - loss: 0.4932 - val_loss: 0.5039\n",
      "learning_rate: 0.00092\n",
      "train loss: 0.4960\n",
      "val loss: 0.5039\n",
      "test loss: 0.4974\n",
      "train,val,test accuracies: 0.27/0.27/0.29\n",
      "training/val losses: 0.493/0.504 ... time taken is 635.76s\n",
      "running iteration 9...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 88s 65ms/step - loss: 0.5015 - val_loss: 0.5028\n",
      "learning_rate: 0.00092\n",
      "train loss: 0.4970\n",
      "val loss: 0.5028\n",
      "test loss: 0.4981\n",
      "train,val,test accuracies: 0.27/0.28/0.26\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4949 - val_loss: 0.5023\n",
      "learning_rate: 0.00092\n",
      "train loss: 0.4974\n",
      "val loss: 0.5023\n",
      "test loss: 0.4985\n",
      "train,val,test accuracies: 0.27/0.28/0.27\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 88s 64ms/step - loss: 0.4991 - val_loss: 0.5022\n",
      "learning_rate: 0.00091\n",
      "train loss: 0.4975\n",
      "val loss: 0.5022\n",
      "test loss: 0.4985\n",
      "train,val,test accuracies: 0.28/0.27/0.27\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 86s 63ms/step - loss: 0.4913 - val_loss: 0.5029\n",
      "learning_rate: 0.00091\n",
      "train loss: 0.4967\n",
      "val loss: 0.5029\n",
      "test loss: 0.4979\n",
      "train,val,test accuracies: 0.28/0.29/0.29\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4907 - val_loss: 0.5042\n",
      "learning_rate: 0.00091\n",
      "train loss: 0.4953\n",
      "val loss: 0.5042\n",
      "test loss: 0.4969\n",
      "train,val,test accuracies: 0.27/0.28/0.29\n",
      "training/val losses: 0.491/0.504 ... time taken is 613.67s\n",
      "running iteration 10...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 89s 65ms/step - loss: 0.4992 - val_loss: 0.5042\n",
      "learning_rate: 0.00091\n",
      "train loss: 0.4953\n",
      "val loss: 0.5042\n",
      "test loss: 0.4970\n",
      "train,val,test accuracies: 0.26/0.30/0.26\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 89s 65ms/step - loss: 0.4942 - val_loss: 0.5045\n",
      "learning_rate: 0.00091\n",
      "train loss: 0.4945\n",
      "val loss: 0.5045\n",
      "test loss: 0.4968\n",
      "train,val,test accuracies: 0.29/0.32/0.29\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 88s 64ms/step - loss: 0.4930 - val_loss: 0.5041\n",
      "learning_rate: 0.00090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 0.4951\n",
      "val loss: 0.5041\n",
      "test loss: 0.4974\n",
      "train,val,test accuracies: 0.29/0.34/0.30\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.5013 - val_loss: 0.5056\n",
      "learning_rate: 0.00090\n",
      "train loss: 0.4937\n",
      "val loss: 0.5056\n",
      "test loss: 0.4971\n",
      "train,val,test accuracies: 0.27/0.35/0.28\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4891 - val_loss: 0.5098\n",
      "learning_rate: 0.00090\n",
      "train loss: 0.4895\n",
      "val loss: 0.5098\n",
      "test loss: 0.4953\n",
      "train,val,test accuracies: 0.28/0.34/0.29\n",
      "training/val losses: 0.489/0.510 ... time taken is 613.49s\n",
      "running iteration 11...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 87s 63ms/step - loss: 0.4858 - val_loss: 0.5138\n",
      "learning_rate: 0.00090\n",
      "train loss: 0.4845\n",
      "val loss: 0.5138\n",
      "test loss: 0.4931\n",
      "train,val,test accuracies: 0.29/0.32/0.27\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 86s 63ms/step - loss: 0.4824 - val_loss: 0.5190\n",
      "learning_rate: 0.00090\n",
      "train loss: 0.4765\n",
      "val loss: 0.5190\n",
      "test loss: 0.4894\n",
      "train,val,test accuracies: 0.29/0.35/0.26\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4839 - val_loss: 0.5222\n",
      "learning_rate: 0.00090\n",
      "train loss: 0.4735\n",
      "val loss: 0.5222\n",
      "test loss: 0.4898\n",
      "train,val,test accuracies: 0.29/0.31/0.27\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 88s 64ms/step - loss: 0.4874 - val_loss: 0.5307\n",
      "learning_rate: 0.00089\n",
      "train loss: 0.4676\n",
      "val loss: 0.5307\n",
      "test loss: 0.4833\n",
      "train,val,test accuracies: 0.30/0.32/0.29\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4845 - val_loss: 0.5377\n",
      "learning_rate: 0.00089\n",
      "train loss: 0.4654\n",
      "val loss: 0.5377\n",
      "test loss: 0.4778\n",
      "train,val,test accuracies: 0.30/0.33/0.28\n",
      "training/val losses: 0.485/0.538 ... time taken is 609.75s\n",
      "running iteration 12...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 88s 65ms/step - loss: 0.4851 - val_loss: 0.5348\n",
      "learning_rate: 0.00089\n",
      "train loss: 0.4628\n",
      "val loss: 0.5348\n",
      "test loss: 0.4770\n",
      "train,val,test accuracies: 0.30/0.31/0.27\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4890 - val_loss: 0.5325\n",
      "learning_rate: 0.00089\n",
      "train loss: 0.4613\n",
      "val loss: 0.5325\n",
      "test loss: 0.4758\n",
      "train,val,test accuracies: 0.29/0.31/0.25\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 88s 65ms/step - loss: 0.4721 - val_loss: 0.5327\n",
      "learning_rate: 0.00089\n",
      "train loss: 0.4587\n",
      "val loss: 0.5327\n",
      "test loss: 0.4759\n",
      "train,val,test accuracies: 0.29/0.31/0.25\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 86s 63ms/step - loss: 0.4747 - val_loss: 0.5271\n",
      "learning_rate: 0.00089\n",
      "train loss: 0.4576\n",
      "val loss: 0.5271\n",
      "test loss: 0.4757\n",
      "train,val,test accuracies: 0.29/0.32/0.25\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 88s 65ms/step - loss: 0.4762 - val_loss: 0.5234\n",
      "learning_rate: 0.00088\n",
      "train loss: 0.4568\n",
      "val loss: 0.5234\n",
      "test loss: 0.4733\n",
      "train,val,test accuracies: 0.32/0.32/0.27\n",
      "training/val losses: 0.476/0.523 ... time taken is 614.74s\n",
      "running iteration 13...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 88s 65ms/step - loss: 0.4670 - val_loss: 0.5222\n",
      "learning_rate: 0.00088\n",
      "train loss: 0.4542\n",
      "val loss: 0.5222\n",
      "test loss: 0.4735\n",
      "train,val,test accuracies: 0.31/0.33/0.27\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 88s 64ms/step - loss: 0.4866 - val_loss: 0.5234\n",
      "learning_rate: 0.00088\n",
      "train loss: 0.4528\n",
      "val loss: 0.5234\n",
      "test loss: 0.4731\n",
      "train,val,test accuracies: 0.31/0.32/0.26\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 83s 61ms/step - loss: 0.4809 - val_loss: 0.5256\n",
      "learning_rate: 0.00088\n",
      "train loss: 0.4525\n",
      "val loss: 0.5256\n",
      "test loss: 0.4729\n",
      "train,val,test accuracies: 0.31/0.33/0.24\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 88s 65ms/step - loss: 0.4631 - val_loss: 0.5248\n",
      "learning_rate: 0.00088\n",
      "train loss: 0.4493\n",
      "val loss: 0.5248\n",
      "test loss: 0.4710\n",
      "train,val,test accuracies: 0.32/0.32/0.24\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 88s 64ms/step - loss: 0.4556 - val_loss: 0.5264\n",
      "learning_rate: 0.00087\n",
      "train loss: 0.4470\n",
      "val loss: 0.5264\n",
      "test loss: 0.4704\n",
      "train,val,test accuracies: 0.33/0.30/0.25\n",
      "training/val losses: 0.456/0.526 ... time taken is 610.69s\n",
      "running iteration 14...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 86s 63ms/step - loss: 0.4635 - val_loss: 0.5248\n",
      "learning_rate: 0.00087\n",
      "train loss: 0.4435\n",
      "val loss: 0.5248\n",
      "test loss: 0.4709\n",
      "train,val,test accuracies: 0.34/0.31/0.26\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4652 - val_loss: 0.5237\n",
      "learning_rate: 0.00087\n",
      "train loss: 0.4415\n",
      "val loss: 0.5237\n",
      "test loss: 0.4699\n",
      "train,val,test accuracies: 0.35/0.30/0.26\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4650 - val_loss: 0.5206\n",
      "learning_rate: 0.00087\n",
      "train loss: 0.4412\n",
      "val loss: 0.5206\n",
      "test loss: 0.4705\n",
      "train,val,test accuracies: 0.35/0.30/0.27\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4597 - val_loss: 0.5239\n",
      "learning_rate: 0.00087\n",
      "train loss: 0.4412\n",
      "val loss: 0.5239\n",
      "test loss: 0.4685\n",
      "train,val,test accuracies: 0.33/0.30/0.26\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4617 - val_loss: 0.5287\n",
      "learning_rate: 0.00087\n",
      "train loss: 0.4396\n",
      "val loss: 0.5287\n",
      "test loss: 0.4669\n",
      "train,val,test accuracies: 0.35/0.29/0.27\n",
      "training/val losses: 0.462/0.529 ... time taken is 609.75s\n",
      "running iteration 15...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4534 - val_loss: 0.5235\n",
      "learning_rate: 0.00086\n",
      "train loss: 0.4346\n",
      "val loss: 0.5235\n",
      "test loss: 0.4667\n",
      "train,val,test accuracies: 0.33/0.27/0.25\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 86s 63ms/step - loss: 0.4562 - val_loss: 0.5300\n",
      "learning_rate: 0.00086\n",
      "train loss: 0.4338\n",
      "val loss: 0.5300\n",
      "test loss: 0.4640\n",
      "train,val,test accuracies: 0.35/0.29/0.27\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4713 - val_loss: 0.5275\n",
      "learning_rate: 0.00086\n",
      "train loss: 0.4366\n",
      "val loss: 0.5275\n",
      "test loss: 0.4677\n",
      "train,val,test accuracies: 0.35/0.28/0.28\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 87s 63ms/step - loss: 0.4638 - val_loss: 0.5301\n",
      "learning_rate: 0.00086\n",
      "train loss: 0.4323\n",
      "val loss: 0.5301\n",
      "test loss: 0.4685\n",
      "train,val,test accuracies: 0.34/0.30/0.25\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 87s 64ms/step - loss: 0.4433 - val_loss: 0.5335\n",
      "learning_rate: 0.00086\n",
      "train loss: 0.4305\n",
      "val loss: 0.5335\n",
      "test loss: 0.4709\n",
      "train,val,test accuracies: 0.35/0.29/0.27\n",
      "training/val losses: 0.443/0.534 ... time taken is 611.55s\n",
      "running iteration 16...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 91s 67ms/step - loss: 0.4634 - val_loss: 0.5341\n",
      "learning_rate: 0.00086\n",
      "train loss: 0.4275\n",
      "val loss: 0.5341\n",
      "test loss: 0.4709\n",
      "train,val,test accuracies: 0.33/0.27/0.28\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 72s 53ms/step - loss: 0.4430 - val_loss: 0.5314\n",
      "learning_rate: 0.00086\n",
      "train loss: 0.4243\n",
      "val loss: 0.5314\n",
      "test loss: 0.4708\n",
      "train,val,test accuracies: 0.36/0.27/0.27\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.4507 - val_loss: 0.5296\n",
      "learning_rate: 0.00085\n",
      "train loss: 0.4246\n",
      "val loss: 0.5296\n",
      "test loss: 0.4666\n",
      "train,val,test accuracies: 0.38/0.28/0.25\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.4385 - val_loss: 0.5308\n",
      "learning_rate: 0.00085\n",
      "train loss: 0.4217\n",
      "val loss: 0.5308\n",
      "test loss: 0.4646\n",
      "train,val,test accuracies: 0.36/0.27/0.25\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.4441 - val_loss: 0.5310\n",
      "learning_rate: 0.00085\n",
      "train loss: 0.4228\n",
      "val loss: 0.5310\n",
      "test loss: 0.4626\n",
      "train,val,test accuracies: 0.35/0.26/0.27\n",
      "training/val losses: 0.444/0.531 ... time taken is 510.90s\n",
      "running iteration 17...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 69s 51ms/step - loss: 0.4483 - val_loss: 0.5344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.00085\n",
      "train loss: 0.4197\n",
      "val loss: 0.5344\n",
      "test loss: 0.4606\n",
      "train,val,test accuracies: 0.36/0.27/0.27\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.4567 - val_loss: 0.5299\n",
      "learning_rate: 0.00085\n",
      "train loss: 0.4185\n",
      "val loss: 0.5299\n",
      "test loss: 0.4606\n",
      "train,val,test accuracies: 0.37/0.29/0.28\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4506 - val_loss: 0.5234\n",
      "learning_rate: 0.00085\n",
      "train loss: 0.4131\n",
      "val loss: 0.5234\n",
      "test loss: 0.4604\n",
      "train,val,test accuracies: 0.36/0.27/0.26\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.4428 - val_loss: 0.5232\n",
      "learning_rate: 0.00084\n",
      "train loss: 0.4132\n",
      "val loss: 0.5232\n",
      "test loss: 0.4612\n",
      "train,val,test accuracies: 0.35/0.27/0.25\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 69s 51ms/step - loss: 0.4455 - val_loss: 0.5208\n",
      "learning_rate: 0.00084\n",
      "train loss: 0.4133\n",
      "val loss: 0.5208\n",
      "test loss: 0.4607\n",
      "train,val,test accuracies: 0.39/0.29/0.26\n",
      "training/val losses: 0.446/0.521 ... time taken is 479.12s\n",
      "running iteration 18...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.4417 - val_loss: 0.5186\n",
      "learning_rate: 0.00084\n",
      "train loss: 0.4122\n",
      "val loss: 0.5186\n",
      "test loss: 0.4600\n",
      "train,val,test accuracies: 0.39/0.29/0.26\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 69s 51ms/step - loss: 0.4362 - val_loss: 0.5145\n",
      "learning_rate: 0.00084\n",
      "train loss: 0.4114\n",
      "val loss: 0.5145\n",
      "test loss: 0.4607\n",
      "train,val,test accuracies: 0.40/0.30/0.25\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 69s 51ms/step - loss: 0.4365 - val_loss: 0.5084\n",
      "learning_rate: 0.00084\n",
      "train loss: 0.4111\n",
      "val loss: 0.5084\n",
      "test loss: 0.4615\n",
      "train,val,test accuracies: 0.41/0.29/0.27\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 73s 54ms/step - loss: 0.4377 - val_loss: 0.5077\n",
      "learning_rate: 0.00084\n",
      "train loss: 0.4092\n",
      "val loss: 0.5077\n",
      "test loss: 0.4637\n",
      "train,val,test accuracies: 0.39/0.31/0.27\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4358 - val_loss: 0.5114\n",
      "learning_rate: 0.00083\n",
      "train loss: 0.4099\n",
      "val loss: 0.5114\n",
      "test loss: 0.4629\n",
      "train,val,test accuracies: 0.39/0.29/0.28\n",
      "training/val losses: 0.436/0.511 ... time taken is 487.80s\n",
      "running iteration 19...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.4444 - val_loss: 0.5122\n",
      "learning_rate: 0.00083\n",
      "train loss: 0.4077\n",
      "val loss: 0.5122\n",
      "test loss: 0.4629\n",
      "train,val,test accuracies: 0.39/0.31/0.28\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 70s 52ms/step - loss: 0.4417 - val_loss: 0.5075\n",
      "learning_rate: 0.00083\n",
      "train loss: 0.4066\n",
      "val loss: 0.5075\n",
      "test loss: 0.4628\n",
      "train,val,test accuracies: 0.37/0.33/0.29\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4360 - val_loss: 0.5030\n",
      "learning_rate: 0.00083\n",
      "train loss: 0.4037\n",
      "val loss: 0.5030\n",
      "test loss: 0.4632\n",
      "train,val,test accuracies: 0.37/0.32/0.29\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4375 - val_loss: 0.5027\n",
      "learning_rate: 0.00083\n",
      "train loss: 0.4012\n",
      "val loss: 0.5027\n",
      "test loss: 0.4613\n",
      "train,val,test accuracies: 0.39/0.33/0.30\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4329 - val_loss: 0.5027\n",
      "learning_rate: 0.00083\n",
      "train loss: 0.3979\n",
      "val loss: 0.5027\n",
      "test loss: 0.4620\n",
      "train,val,test accuracies: 0.39/0.33/0.31\n",
      "training/val losses: 0.433/0.503 ... time taken is 476.58s\n",
      "running iteration 20...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4393 - val_loss: 0.4973\n",
      "learning_rate: 0.00083\n",
      "train loss: 0.4008\n",
      "val loss: 0.4973\n",
      "test loss: 0.4596\n",
      "train,val,test accuracies: 0.37/0.34/0.31\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.4298 - val_loss: 0.4993\n",
      "learning_rate: 0.00082\n",
      "train loss: 0.3958\n",
      "val loss: 0.4993\n",
      "test loss: 0.4571\n",
      "train,val,test accuracies: 0.39/0.33/0.31\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4218 - val_loss: 0.5012\n",
      "learning_rate: 0.00082\n",
      "train loss: 0.3919\n",
      "val loss: 0.5012\n",
      "test loss: 0.4562\n",
      "train,val,test accuracies: 0.40/0.33/0.29\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4233 - val_loss: 0.5011\n",
      "learning_rate: 0.00082\n",
      "train loss: 0.3902\n",
      "val loss: 0.5011\n",
      "test loss: 0.4542\n",
      "train,val,test accuracies: 0.41/0.32/0.31\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4188 - val_loss: 0.4978\n",
      "learning_rate: 0.00082\n",
      "train loss: 0.3933\n",
      "val loss: 0.4978\n",
      "test loss: 0.4539\n",
      "train,val,test accuracies: 0.43/0.32/0.33\n",
      "training/val losses: 0.419/0.498 ... time taken is 466.07s\n",
      "running iteration 21...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4256 - val_loss: 0.4961\n",
      "learning_rate: 0.00082\n",
      "train loss: 0.3934\n",
      "val loss: 0.4961\n",
      "test loss: 0.4520\n",
      "train,val,test accuracies: 0.45/0.32/0.33\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4285 - val_loss: 0.4964\n",
      "learning_rate: 0.00082\n",
      "train loss: 0.3880\n",
      "val loss: 0.4964\n",
      "test loss: 0.4507\n",
      "train,val,test accuracies: 0.43/0.31/0.32\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.4182 - val_loss: 0.4962\n",
      "learning_rate: 0.00082\n",
      "train loss: 0.3834\n",
      "val loss: 0.4962\n",
      "test loss: 0.4528\n",
      "train,val,test accuracies: 0.42/0.30/0.31\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4283 - val_loss: 0.4954\n",
      "learning_rate: 0.00081\n",
      "train loss: 0.3844\n",
      "val loss: 0.4954\n",
      "test loss: 0.4457\n",
      "train,val,test accuracies: 0.44/0.31/0.31\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.4201 - val_loss: 0.4975\n",
      "learning_rate: 0.00081\n",
      "train loss: 0.3830\n",
      "val loss: 0.4975\n",
      "test loss: 0.4461\n",
      "train,val,test accuracies: 0.47/0.31/0.32\n",
      "training/val losses: 0.420/0.497 ... time taken is 468.53s\n",
      "running iteration 22...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4222 - val_loss: 0.4984\n",
      "learning_rate: 0.00081\n",
      "train loss: 0.3798\n",
      "val loss: 0.4984\n",
      "test loss: 0.4485\n",
      "train,val,test accuracies: 0.43/0.31/0.30\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4199 - val_loss: 0.5003\n",
      "learning_rate: 0.00081\n",
      "train loss: 0.3824\n",
      "val loss: 0.5003\n",
      "test loss: 0.4431\n",
      "train,val,test accuracies: 0.47/0.29/0.31\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4169 - val_loss: 0.5020\n",
      "learning_rate: 0.00081\n",
      "train loss: 0.3783\n",
      "val loss: 0.5020\n",
      "test loss: 0.4446\n",
      "train,val,test accuracies: 0.45/0.31/0.31\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4074 - val_loss: 0.5050\n",
      "learning_rate: 0.00081\n",
      "train loss: 0.3779\n",
      "val loss: 0.5050\n",
      "test loss: 0.4395\n",
      "train,val,test accuracies: 0.45/0.32/0.30\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.4147 - val_loss: 0.5035\n",
      "learning_rate: 0.00081\n",
      "train loss: 0.3759\n",
      "val loss: 0.5035\n",
      "test loss: 0.4407\n",
      "train,val,test accuracies: 0.45/0.32/0.31\n",
      "training/val losses: 0.415/0.503 ... time taken is 466.84s\n",
      "running iteration 23...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4100 - val_loss: 0.5019\n",
      "learning_rate: 0.00080\n",
      "train loss: 0.3738\n",
      "val loss: 0.5019\n",
      "test loss: 0.4411\n",
      "train,val,test accuracies: 0.43/0.33/0.31\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.4206 - val_loss: 0.4975\n",
      "learning_rate: 0.00080\n",
      "train loss: 0.3731\n",
      "val loss: 0.4975\n",
      "test loss: 0.4432\n",
      "train,val,test accuracies: 0.47/0.32/0.35\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.4136 - val_loss: 0.4967\n",
      "learning_rate: 0.00080\n",
      "train loss: 0.3690\n",
      "val loss: 0.4967\n",
      "test loss: 0.4465\n",
      "train,val,test accuracies: 0.47/0.32/0.34\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4063 - val_loss: 0.4926\n",
      "learning_rate: 0.00080\n",
      "train loss: 0.3693\n",
      "val loss: 0.4926\n",
      "test loss: 0.4459\n",
      "train,val,test accuracies: 0.46/0.31/0.33\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.4012 - val_loss: 0.4959\n",
      "learning_rate: 0.00080\n",
      "train loss: 0.3667\n",
      "val loss: 0.4959\n",
      "test loss: 0.4426\n",
      "train,val,test accuracies: 0.47/0.30/0.31\n",
      "training/val losses: 0.401/0.496 ... time taken is 467.04s\n",
      "running iteration 24...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.4140 - val_loss: 0.4921\n",
      "learning_rate: 0.00080\n",
      "train loss: 0.3699\n",
      "val loss: 0.4921\n",
      "test loss: 0.4390\n",
      "train,val,test accuracies: 0.51/0.31/0.33\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4148 - val_loss: 0.4919\n",
      "learning_rate: 0.00080\n",
      "train loss: 0.3670\n",
      "val loss: 0.4919\n",
      "test loss: 0.4356\n",
      "train,val,test accuracies: 0.47/0.32/0.31\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4027 - val_loss: 0.4910\n",
      "learning_rate: 0.00079\n",
      "train loss: 0.3654\n",
      "val loss: 0.4910\n",
      "test loss: 0.4347\n",
      "train,val,test accuracies: 0.48/0.30/0.32\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3987 - val_loss: 0.4904\n",
      "learning_rate: 0.00079\n",
      "train loss: 0.3611\n",
      "val loss: 0.4904\n",
      "test loss: 0.4336\n",
      "train,val,test accuracies: 0.47/0.29/0.32\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4016 - val_loss: 0.4934\n",
      "learning_rate: 0.00079\n",
      "train loss: 0.3608\n",
      "val loss: 0.4934\n",
      "test loss: 0.4314\n",
      "train,val,test accuracies: 0.49/0.29/0.32\n",
      "training/val losses: 0.402/0.493 ... time taken is 467.11s\n",
      "running iteration 25...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.4105 - val_loss: 0.4912\n",
      "learning_rate: 0.00079\n",
      "train loss: 0.3619\n",
      "val loss: 0.4912\n",
      "test loss: 0.4335\n",
      "train,val,test accuracies: 0.47/0.29/0.31\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3955 - val_loss: 0.4906\n",
      "learning_rate: 0.00079\n",
      "train loss: 0.3603\n",
      "val loss: 0.4906\n",
      "test loss: 0.4360\n",
      "train,val,test accuracies: 0.48/0.29/0.33\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.4006 - val_loss: 0.4885\n",
      "learning_rate: 0.00079\n",
      "train loss: 0.3579\n",
      "val loss: 0.4885\n",
      "test loss: 0.4354\n",
      "train,val,test accuracies: 0.46/0.29/0.33\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4001 - val_loss: 0.4907\n",
      "learning_rate: 0.00079\n",
      "train loss: 0.3566\n",
      "val loss: 0.4907\n",
      "test loss: 0.4376\n",
      "train,val,test accuracies: 0.48/0.29/0.31\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4016 - val_loss: 0.4915\n",
      "learning_rate: 0.00078\n",
      "train loss: 0.3580\n",
      "val loss: 0.4915\n",
      "test loss: 0.4365\n",
      "train,val,test accuracies: 0.52/0.29/0.31\n",
      "training/val losses: 0.402/0.491 ... time taken is 464.50s\n",
      "running iteration 26...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3956 - val_loss: 0.4896\n",
      "learning_rate: 0.00078\n",
      "train loss: 0.3590\n",
      "val loss: 0.4896\n",
      "test loss: 0.4376\n",
      "train,val,test accuracies: 0.51/0.30/0.32\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3988 - val_loss: 0.4877\n",
      "learning_rate: 0.00078\n",
      "train loss: 0.3566\n",
      "val loss: 0.4877\n",
      "test loss: 0.4409\n",
      "train,val,test accuracies: 0.46/0.29/0.33\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3888 - val_loss: 0.4877\n",
      "learning_rate: 0.00078\n",
      "train loss: 0.3546\n",
      "val loss: 0.4877\n",
      "test loss: 0.4384\n",
      "train,val,test accuracies: 0.47/0.29/0.33\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3924 - val_loss: 0.4835\n",
      "learning_rate: 0.00078\n",
      "train loss: 0.3554\n",
      "val loss: 0.4835\n",
      "test loss: 0.4378\n",
      "train,val,test accuracies: 0.48/0.30/0.34\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.4063 - val_loss: 0.4839\n",
      "learning_rate: 0.00078\n",
      "train loss: 0.3524\n",
      "val loss: 0.4839\n",
      "test loss: 0.4433\n",
      "train,val,test accuracies: 0.44/0.29/0.32\n",
      "training/val losses: 0.406/0.484 ... time taken is 466.01s\n",
      "running iteration 27...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.4003 - val_loss: 0.4844\n",
      "learning_rate: 0.00078\n",
      "train loss: 0.3519\n",
      "val loss: 0.4844\n",
      "test loss: 0.4447\n",
      "train,val,test accuracies: 0.45/0.29/0.33\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3964 - val_loss: 0.4883\n",
      "learning_rate: 0.00077\n",
      "train loss: 0.3502\n",
      "val loss: 0.4883\n",
      "test loss: 0.4399\n",
      "train,val,test accuracies: 0.49/0.30/0.33\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3950 - val_loss: 0.4916\n",
      "learning_rate: 0.00077\n",
      "train loss: 0.3478\n",
      "val loss: 0.4916\n",
      "test loss: 0.4434\n",
      "train,val,test accuracies: 0.47/0.32/0.34\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.4035 - val_loss: 0.4984\n",
      "learning_rate: 0.00077\n",
      "train loss: 0.3486\n",
      "val loss: 0.4984\n",
      "test loss: 0.4439\n",
      "train,val,test accuracies: 0.48/0.30/0.32\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.3975 - val_loss: 0.4970\n",
      "learning_rate: 0.00077\n",
      "train loss: 0.3491\n",
      "val loss: 0.4970\n",
      "test loss: 0.4426\n",
      "train,val,test accuracies: 0.45/0.29/0.33\n",
      "training/val losses: 0.398/0.497 ... time taken is 473.11s\n",
      "running iteration 28...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3867 - val_loss: 0.4990\n",
      "learning_rate: 0.00077\n",
      "train loss: 0.3448\n",
      "val loss: 0.4990\n",
      "test loss: 0.4455\n",
      "train,val,test accuracies: 0.45/0.27/0.32\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3954 - val_loss: 0.4955\n",
      "learning_rate: 0.00077\n",
      "train loss: 0.3501\n",
      "val loss: 0.4955\n",
      "test loss: 0.4386\n",
      "train,val,test accuracies: 0.51/0.28/0.33\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3979 - val_loss: 0.4975\n",
      "learning_rate: 0.00077\n",
      "train loss: 0.3423\n",
      "val loss: 0.4975\n",
      "test loss: 0.4483\n",
      "train,val,test accuracies: 0.47/0.27/0.31\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3809 - val_loss: 0.4973\n",
      "learning_rate: 0.00077\n",
      "train loss: 0.3430\n",
      "val loss: 0.4973\n",
      "test loss: 0.4462\n",
      "train,val,test accuracies: 0.48/0.27/0.33\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3780 - val_loss: 0.4984\n",
      "learning_rate: 0.00076\n",
      "train loss: 0.3419\n",
      "val loss: 0.4984\n",
      "test loss: 0.4460\n",
      "train,val,test accuracies: 0.50/0.27/0.32\n",
      "training/val losses: 0.378/0.498 ... time taken is 467.66s\n",
      "running iteration 29...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3851 - val_loss: 0.4982\n",
      "learning_rate: 0.00076\n",
      "train loss: 0.3416\n",
      "val loss: 0.4982\n",
      "test loss: 0.4448\n",
      "train,val,test accuracies: 0.47/0.28/0.31\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3928 - val_loss: 0.4926\n",
      "learning_rate: 0.00076\n",
      "train loss: 0.3397\n",
      "val loss: 0.4926\n",
      "test loss: 0.4408\n",
      "train,val,test accuracies: 0.48/0.27/0.33\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.3866 - val_loss: 0.4890\n",
      "learning_rate: 0.00076\n",
      "train loss: 0.3392\n",
      "val loss: 0.4890\n",
      "test loss: 0.4416\n",
      "train,val,test accuracies: 0.48/0.27/0.34\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 70s 51ms/step - loss: 0.3878 - val_loss: 0.4830\n",
      "learning_rate: 0.00076\n",
      "train loss: 0.3394\n",
      "val loss: 0.4830\n",
      "test loss: 0.4479\n",
      "train,val,test accuracies: 0.50/0.31/0.33\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3918 - val_loss: 0.4839\n",
      "learning_rate: 0.00076\n",
      "train loss: 0.3404\n",
      "val loss: 0.4839\n",
      "test loss: 0.4405\n",
      "train,val,test accuracies: 0.49/0.29/0.33\n",
      "training/val losses: 0.392/0.484 ... time taken is 476.56s\n",
      "running iteration 30...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3843 - val_loss: 0.4814\n",
      "learning_rate: 0.00076\n",
      "train loss: 0.3362\n",
      "val loss: 0.4814\n",
      "test loss: 0.4403\n",
      "train,val,test accuracies: 0.49/0.29/0.33\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.3914 - val_loss: 0.4792\n",
      "learning_rate: 0.00076\n",
      "train loss: 0.3381\n",
      "val loss: 0.4792\n",
      "test loss: 0.4340\n",
      "train,val,test accuracies: 0.49/0.29/0.34\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.3873 - val_loss: 0.4815\n",
      "learning_rate: 0.00075\n",
      "train loss: 0.3428\n",
      "val loss: 0.4815\n",
      "test loss: 0.4318\n",
      "train,val,test accuracies: 0.49/0.29/0.35\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3879 - val_loss: 0.4854\n",
      "learning_rate: 0.00075\n",
      "train loss: 0.3357\n",
      "val loss: 0.4854\n",
      "test loss: 0.4353\n",
      "train,val,test accuracies: 0.46/0.29/0.33\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.3957 - val_loss: 0.4878\n",
      "learning_rate: 0.00075\n",
      "train loss: 0.3368\n",
      "val loss: 0.4878\n",
      "test loss: 0.4444\n",
      "train,val,test accuracies: 0.47/0.29/0.33\n",
      "training/val losses: 0.396/0.488 ... time taken is 464.26s\n",
      "running iteration 31...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3974 - val_loss: 0.4857\n",
      "learning_rate: 0.00075\n",
      "train loss: 0.3375\n",
      "val loss: 0.4857\n",
      "test loss: 0.4420\n",
      "train,val,test accuracies: 0.47/0.27/0.32\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.3789 - val_loss: 0.4908\n",
      "learning_rate: 0.00075\n",
      "train loss: 0.3337\n",
      "val loss: 0.4908\n",
      "test loss: 0.4453\n",
      "train,val,test accuracies: 0.48/0.28/0.33\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 64s 47ms/step - loss: 0.3892 - val_loss: 0.4939\n",
      "learning_rate: 0.00075\n",
      "train loss: 0.3362\n",
      "val loss: 0.4939\n",
      "test loss: 0.4434\n",
      "train,val,test accuracies: 0.51/0.28/0.36\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 64s 47ms/step - loss: 0.3784 - val_loss: 0.4924\n",
      "learning_rate: 0.00075\n",
      "train loss: 0.3344\n",
      "val loss: 0.4924\n",
      "test loss: 0.4467\n",
      "train,val,test accuracies: 0.49/0.28/0.35\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3675 - val_loss: 0.4885\n",
      "learning_rate: 0.00075\n",
      "train loss: 0.3327\n",
      "val loss: 0.4885\n",
      "test loss: 0.4489\n",
      "train,val,test accuracies: 0.47/0.29/0.35\n",
      "training/val losses: 0.368/0.489 ... time taken is 465.77s\n",
      "running iteration 32...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.3621 - val_loss: 0.4920\n",
      "learning_rate: 0.00074\n",
      "train loss: 0.3300\n",
      "val loss: 0.4920\n",
      "test loss: 0.4498\n",
      "train,val,test accuracies: 0.47/0.28/0.34\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3701 - val_loss: 0.4948\n",
      "learning_rate: 0.00074\n",
      "train loss: 0.3290\n",
      "val loss: 0.4948\n",
      "test loss: 0.4447\n",
      "train,val,test accuracies: 0.50/0.29/0.35\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3779 - val_loss: 0.4937\n",
      "learning_rate: 0.00074\n",
      "train loss: 0.3298\n",
      "val loss: 0.4937\n",
      "test loss: 0.4422\n",
      "train,val,test accuracies: 0.51/0.29/0.35\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3654 - val_loss: 0.4947\n",
      "learning_rate: 0.00074\n",
      "train loss: 0.3285\n",
      "val loss: 0.4947\n",
      "test loss: 0.4448\n",
      "train,val,test accuracies: 0.49/0.29/0.35\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3669 - val_loss: 0.5000\n",
      "learning_rate: 0.00074\n",
      "train loss: 0.3284\n",
      "val loss: 0.5000\n",
      "test loss: 0.4474\n",
      "train,val,test accuracies: 0.51/0.28/0.33\n",
      "training/val losses: 0.367/0.500 ... time taken is 469.15s\n",
      "running iteration 33...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3721 - val_loss: 0.5015\n",
      "learning_rate: 0.00074\n",
      "train loss: 0.3292\n",
      "val loss: 0.5015\n",
      "test loss: 0.4423\n",
      "train,val,test accuracies: 0.52/0.29/0.33\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3598 - val_loss: 0.5014\n",
      "learning_rate: 0.00074\n",
      "train loss: 0.3272\n",
      "val loss: 0.5014\n",
      "test loss: 0.4362\n",
      "train,val,test accuracies: 0.51/0.30/0.35\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3783 - val_loss: 0.5065\n",
      "learning_rate: 0.00074\n",
      "train loss: 0.3277\n",
      "val loss: 0.5065\n",
      "test loss: 0.4340\n",
      "train,val,test accuracies: 0.51/0.31/0.36\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3721 - val_loss: 0.5035\n",
      "learning_rate: 0.00073\n",
      "train loss: 0.3280\n",
      "val loss: 0.5035\n",
      "test loss: 0.4318\n",
      "train,val,test accuracies: 0.52/0.31/0.37\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3721 - val_loss: 0.4997\n",
      "learning_rate: 0.00073\n",
      "train loss: 0.3298\n",
      "val loss: 0.4997\n",
      "test loss: 0.4328\n",
      "train,val,test accuracies: 0.55/0.32/0.37\n",
      "training/val losses: 0.372/0.500 ... time taken is 477.36s\n",
      "running iteration 34...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 69s 50ms/step - loss: 0.3752 - val_loss: 0.4948\n",
      "learning_rate: 0.00073\n",
      "train loss: 0.3288\n",
      "val loss: 0.4948\n",
      "test loss: 0.4385\n",
      "train,val,test accuracies: 0.51/0.31/0.35\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3781 - val_loss: 0.4953\n",
      "learning_rate: 0.00073\n",
      "train loss: 0.3274\n",
      "val loss: 0.4953\n",
      "test loss: 0.4342\n",
      "train,val,test accuracies: 0.52/0.32/0.35\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3574 - val_loss: 0.4995\n",
      "learning_rate: 0.00073\n",
      "train loss: 0.3285\n",
      "val loss: 0.4995\n",
      "test loss: 0.4384\n",
      "train,val,test accuracies: 0.54/0.30/0.35\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3593 - val_loss: 0.4977\n",
      "learning_rate: 0.00073\n",
      "train loss: 0.3242\n",
      "val loss: 0.4977\n",
      "test loss: 0.4445\n",
      "train,val,test accuracies: 0.52/0.30/0.33\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3638 - val_loss: 0.5003\n",
      "learning_rate: 0.00073\n",
      "train loss: 0.3245\n",
      "val loss: 0.5003\n",
      "test loss: 0.4448\n",
      "train,val,test accuracies: 0.55/0.29/0.34\n",
      "training/val losses: 0.364/0.500 ... time taken is 480.66s\n",
      "running iteration 35...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.3637 - val_loss: 0.4999\n",
      "learning_rate: 0.00073\n",
      "train loss: 0.3221\n",
      "val loss: 0.4999\n",
      "test loss: 0.4450\n",
      "train,val,test accuracies: 0.54/0.28/0.33\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3553 - val_loss: 0.4974\n",
      "learning_rate: 0.00073\n",
      "train loss: 0.3213\n",
      "val loss: 0.4974\n",
      "test loss: 0.4410\n",
      "train,val,test accuracies: 0.51/0.30/0.32\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3737 - val_loss: 0.4991\n",
      "learning_rate: 0.00072\n",
      "train loss: 0.3229\n",
      "val loss: 0.4991\n",
      "test loss: 0.4352\n",
      "train,val,test accuracies: 0.51/0.29/0.33\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 65s 47ms/step - loss: 0.3674 - val_loss: 0.4945\n",
      "learning_rate: 0.00072\n",
      "train loss: 0.3214\n",
      "val loss: 0.4945\n",
      "test loss: 0.4326\n",
      "train,val,test accuracies: 0.54/0.31/0.35\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3608 - val_loss: 0.4965\n",
      "learning_rate: 0.00072\n",
      "train loss: 0.3202\n",
      "val loss: 0.4965\n",
      "test loss: 0.4324\n",
      "train,val,test accuracies: 0.54/0.30/0.36\n",
      "training/val losses: 0.361/0.497 ... time taken is 471.77s\n",
      "running iteration 36...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3791 - val_loss: 0.4980\n",
      "learning_rate: 0.00072\n",
      "train loss: 0.3189\n",
      "val loss: 0.4980\n",
      "test loss: 0.4307\n",
      "train,val,test accuracies: 0.53/0.29/0.35\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 66s 49ms/step - loss: 0.3733 - val_loss: 0.5006\n",
      "learning_rate: 0.00072\n",
      "train loss: 0.3185\n",
      "val loss: 0.5006\n",
      "test loss: 0.4324\n",
      "train,val,test accuracies: 0.53/0.29/0.35\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3682 - val_loss: 0.5004\n",
      "learning_rate: 0.00072\n",
      "train loss: 0.3274\n",
      "val loss: 0.5004\n",
      "test loss: 0.4324\n",
      "train,val,test accuracies: 0.55/0.29/0.38\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3685 - val_loss: 0.5007\n",
      "learning_rate: 0.00072\n",
      "train loss: 0.3268\n",
      "val loss: 0.5007\n",
      "test loss: 0.4327\n",
      "train,val,test accuracies: 0.55/0.29/0.37\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3644 - val_loss: 0.4985\n",
      "learning_rate: 0.00072\n",
      "train loss: 0.3223\n",
      "val loss: 0.4985\n",
      "test loss: 0.4296\n",
      "train,val,test accuracies: 0.50/0.29/0.35\n",
      "training/val losses: 0.364/0.498 ... time taken is 476.91s\n",
      "running iteration 37...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3749 - val_loss: 0.4970\n",
      "learning_rate: 0.00072\n",
      "train loss: 0.3201\n",
      "val loss: 0.4970\n",
      "test loss: 0.4271\n",
      "train,val,test accuracies: 0.51/0.30/0.36\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3795 - val_loss: 0.4908\n",
      "learning_rate: 0.00071\n",
      "train loss: 0.3183\n",
      "val loss: 0.4908\n",
      "test loss: 0.4264\n",
      "train,val,test accuracies: 0.53/0.30/0.35\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 70s 51ms/step - loss: 0.3587 - val_loss: 0.4940\n",
      "learning_rate: 0.00071\n",
      "train loss: 0.3186\n",
      "val loss: 0.4940\n",
      "test loss: 0.4281\n",
      "train,val,test accuracies: 0.53/0.29/0.37\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3610 - val_loss: 0.4941\n",
      "learning_rate: 0.00071\n",
      "train loss: 0.3149\n",
      "val loss: 0.4941\n",
      "test loss: 0.4266\n",
      "train,val,test accuracies: 0.54/0.31/0.36\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3545 - val_loss: 0.4941\n",
      "learning_rate: 0.00071\n",
      "train loss: 0.3144\n",
      "val loss: 0.4941\n",
      "test loss: 0.4261\n",
      "train,val,test accuracies: 0.54/0.30/0.36\n",
      "training/val losses: 0.355/0.494 ... time taken is 482.89s\n",
      "running iteration 38...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 69s 50ms/step - loss: 0.3746 - val_loss: 0.4950\n",
      "learning_rate: 0.00071\n",
      "train loss: 0.3126\n",
      "val loss: 0.4950\n",
      "test loss: 0.4289\n",
      "train,val,test accuracies: 0.53/0.29/0.35\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 69s 50ms/step - loss: 0.3572 - val_loss: 0.4983\n",
      "learning_rate: 0.00071\n",
      "train loss: 0.3124\n",
      "val loss: 0.4983\n",
      "test loss: 0.4269\n",
      "train,val,test accuracies: 0.53/0.29/0.35\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 71s 52ms/step - loss: 0.3677 - val_loss: 0.5000\n",
      "learning_rate: 0.00071\n",
      "train loss: 0.3106\n",
      "val loss: 0.5000\n",
      "test loss: 0.4282\n",
      "train,val,test accuracies: 0.53/0.29/0.34\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 69s 51ms/step - loss: 0.3498 - val_loss: 0.5036\n",
      "learning_rate: 0.00071\n",
      "train loss: 0.3100\n",
      "val loss: 0.5036\n",
      "test loss: 0.4312\n",
      "train,val,test accuracies: 0.53/0.30/0.35\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3635 - val_loss: 0.4946\n",
      "learning_rate: 0.00071\n",
      "train loss: 0.3122\n",
      "val loss: 0.4946\n",
      "test loss: 0.4251\n",
      "train,val,test accuracies: 0.52/0.31/0.38\n",
      "training/val losses: 0.364/0.495 ... time taken is 486.14s\n",
      "running iteration 39...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 67s 50ms/step - loss: 0.3775 - val_loss: 0.4889\n",
      "learning_rate: 0.00070\n",
      "train loss: 0.3108\n",
      "val loss: 0.4889\n",
      "test loss: 0.4207\n",
      "train,val,test accuracies: 0.54/0.31/0.39\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3747 - val_loss: 0.4852\n",
      "learning_rate: 0.00070\n",
      "train loss: 0.3113\n",
      "val loss: 0.4852\n",
      "test loss: 0.4207\n",
      "train,val,test accuracies: 0.54/0.31/0.38\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 69s 51ms/step - loss: 0.3568 - val_loss: 0.4872\n",
      "learning_rate: 0.00070\n",
      "train loss: 0.3091\n",
      "val loss: 0.4872\n",
      "test loss: 0.4258\n",
      "train,val,test accuracies: 0.53/0.31/0.37\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3481 - val_loss: 0.4853\n",
      "learning_rate: 0.00070\n",
      "train loss: 0.3077\n",
      "val loss: 0.4853\n",
      "test loss: 0.4288\n",
      "train,val,test accuracies: 0.51/0.33/0.37\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 69s 50ms/step - loss: 0.3586 - val_loss: 0.4844\n",
      "learning_rate: 0.00070\n",
      "train loss: 0.3087\n",
      "val loss: 0.4844\n",
      "test loss: 0.4309\n",
      "train,val,test accuracies: 0.49/0.31/0.37\n",
      "training/val losses: 0.359/0.484 ... time taken is 480.30s\n",
      "running iteration 40...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 76s 56ms/step - loss: 0.3655 - val_loss: 0.4837\n",
      "learning_rate: 0.00070\n",
      "train loss: 0.3094\n",
      "val loss: 0.4837\n",
      "test loss: 0.4248\n",
      "train,val,test accuracies: 0.51/0.31/0.40\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3528 - val_loss: 0.4821\n",
      "learning_rate: 0.00070\n",
      "train loss: 0.3077\n",
      "val loss: 0.4821\n",
      "test loss: 0.4202\n",
      "train,val,test accuracies: 0.52/0.31/0.38\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3626 - val_loss: 0.4803\n",
      "learning_rate: 0.00070\n",
      "train loss: 0.3062\n",
      "val loss: 0.4803\n",
      "test loss: 0.4207\n",
      "train,val,test accuracies: 0.52/0.31/0.40\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3605 - val_loss: 0.4797\n",
      "learning_rate: 0.00070\n",
      "train loss: 0.3073\n",
      "val loss: 0.4797\n",
      "test loss: 0.4199\n",
      "train,val,test accuracies: 0.54/0.31/0.41\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 70s 51ms/step - loss: 0.3604 - val_loss: 0.4832\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3110\n",
      "val loss: 0.4832\n",
      "test loss: 0.4226\n",
      "train,val,test accuracies: 0.59/0.31/0.41\n",
      "training/val losses: 0.360/0.483 ... time taken is 497.98s\n",
      "running iteration 41...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 68s 50ms/step - loss: 0.3609 - val_loss: 0.4800\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3061\n",
      "val loss: 0.4800\n",
      "test loss: 0.4304\n",
      "train,val,test accuracies: 0.56/0.31/0.37\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 73s 54ms/step - loss: 0.3665 - val_loss: 0.4773\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3059\n",
      "val loss: 0.4773\n",
      "test loss: 0.4284\n",
      "train,val,test accuracies: 0.54/0.31/0.39\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 69s 50ms/step - loss: 0.3612 - val_loss: 0.4765\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3070\n",
      "val loss: 0.4765\n",
      "test loss: 0.4262\n",
      "train,val,test accuracies: 0.55/0.32/0.40\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3564 - val_loss: 0.4775\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3073\n",
      "val loss: 0.4775\n",
      "test loss: 0.4305\n",
      "train,val,test accuracies: 0.52/0.32/0.37\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3598 - val_loss: 0.4753\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3099\n",
      "val loss: 0.4753\n",
      "test loss: 0.4295\n",
      "train,val,test accuracies: 0.53/0.32/0.39\n",
      "training/val losses: 0.360/0.475 ... time taken is 483.76s\n",
      "running iteration 42...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3639 - val_loss: 0.4751\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3062\n",
      "val loss: 0.4751\n",
      "test loss: 0.4294\n",
      "train,val,test accuracies: 0.54/0.32/0.39\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 70s 51ms/step - loss: 0.3691 - val_loss: 0.4757\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3066\n",
      "val loss: 0.4757\n",
      "test loss: 0.4312\n",
      "train,val,test accuracies: 0.53/0.31/0.40\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 69s 51ms/step - loss: 0.3581 - val_loss: 0.4729\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3062\n",
      "val loss: 0.4729\n",
      "test loss: 0.4287\n",
      "train,val,test accuracies: 0.51/0.32/0.37\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3534 - val_loss: 0.4703\n",
      "learning_rate: 0.00069\n",
      "train loss: 0.3040\n",
      "val loss: 0.4703\n",
      "test loss: 0.4301\n",
      "train,val,test accuracies: 0.51/0.33/0.37\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 67s 49ms/step - loss: 0.3366 - val_loss: 0.4740\n",
      "learning_rate: 0.00068\n",
      "train loss: 0.3029\n",
      "val loss: 0.4740\n",
      "test loss: 0.4303\n",
      "train,val,test accuracies: 0.51/0.33/0.39\n",
      "training/val losses: 0.337/0.474 ... time taken is 478.18s\n",
      "running iteration 43...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3441 - val_loss: 0.4654\n",
      "learning_rate: 0.00068\n",
      "train loss: 0.3041\n",
      "val loss: 0.4654\n",
      "test loss: 0.4304\n",
      "train,val,test accuracies: 0.53/0.30/0.37\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 65s 47ms/step - loss: 0.3532 - val_loss: 0.4667\n",
      "learning_rate: 0.00068\n",
      "train loss: 0.3022\n",
      "val loss: 0.4667\n",
      "test loss: 0.4298\n",
      "train,val,test accuracies: 0.53/0.31/0.39\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3599 - val_loss: 0.4650\n",
      "learning_rate: 0.00068\n",
      "train loss: 0.3081\n",
      "val loss: 0.4650\n",
      "test loss: 0.4308\n",
      "train,val,test accuracies: 0.56/0.31/0.39\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3572 - val_loss: 0.4627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate: 0.00068\n",
      "train loss: 0.3029\n",
      "val loss: 0.4627\n",
      "test loss: 0.4343\n",
      "train,val,test accuracies: 0.52/0.30/0.39\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3523 - val_loss: 0.4637\n",
      "learning_rate: 0.00068\n",
      "train loss: 0.3033\n",
      "val loss: 0.4637\n",
      "test loss: 0.4349\n",
      "train,val,test accuracies: 0.51/0.30/0.39\n",
      "training/val losses: 0.352/0.464 ... time taken is 465.85s\n",
      "running iteration 44...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3683 - val_loss: 0.4676\n",
      "learning_rate: 0.00068\n",
      "train loss: 0.3122\n",
      "val loss: 0.4676\n",
      "test loss: 0.4274\n",
      "train,val,test accuracies: 0.56/0.32/0.40\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3731 - val_loss: 0.4656\n",
      "learning_rate: 0.00068\n",
      "train loss: 0.3028\n",
      "val loss: 0.4656\n",
      "test loss: 0.4229\n",
      "train,val,test accuracies: 0.55/0.32/0.38\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3634 - val_loss: 0.4675\n",
      "learning_rate: 0.00068\n",
      "train loss: 0.3015\n",
      "val loss: 0.4675\n",
      "test loss: 0.4206\n",
      "train,val,test accuracies: 0.55/0.31/0.39\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3432 - val_loss: 0.4677\n",
      "learning_rate: 0.00067\n",
      "train loss: 0.3007\n",
      "val loss: 0.4677\n",
      "test loss: 0.4182\n",
      "train,val,test accuracies: 0.55/0.33/0.40\n",
      "Epoch 5/5\n",
      "1363/1363 [==============================] - 66s 48ms/step - loss: 0.3584 - val_loss: 0.4651\n",
      "learning_rate: 0.00067\n",
      "train loss: 0.3024\n",
      "val loss: 0.4651\n",
      "test loss: 0.4146\n",
      "train,val,test accuracies: 0.55/0.31/0.41\n",
      "training/val losses: 0.358/0.465 ... time taken is 464.34s\n",
      "running iteration 45...Train on 1363 samples, validate on 150 samples\n",
      "Epoch 1/5\n",
      "1363/1363 [==============================] - 64s 47ms/step - loss: 0.3542 - val_loss: 0.4669\n",
      "learning_rate: 0.00067\n",
      "train loss: 0.3026\n",
      "val loss: 0.4669\n",
      "test loss: 0.4123\n",
      "train,val,test accuracies: 0.57/0.31/0.41\n",
      "Epoch 2/5\n",
      "1363/1363 [==============================] - 64s 47ms/step - loss: 0.3547 - val_loss: 0.4665\n",
      "learning_rate: 0.00067\n",
      "train loss: 0.3004\n",
      "val loss: 0.4665\n",
      "test loss: 0.4130\n",
      "train,val,test accuracies: 0.58/0.30/0.41\n",
      "Epoch 3/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3481 - val_loss: 0.4660\n",
      "learning_rate: 0.00067\n",
      "train loss: 0.2994\n",
      "val loss: 0.4660\n",
      "test loss: 0.4158\n",
      "train,val,test accuracies: 0.55/0.31/0.41\n",
      "Epoch 4/5\n",
      "1363/1363 [==============================] - 65s 48ms/step - loss: 0.3543 - val_loss: 0.4634\n",
      "learning_rate: 0.00067\n",
      "train loss: 0.3002\n",
      "val loss: 0.4634\n",
      "test loss: 0.4161\n",
      "train,val,test accuracies: 0.57/0.31/0.41\n",
      "Epoch 5/5\n",
      " 832/1363 [=================>............] - ETA: 24s - loss: 0.3572"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-415907bfa4a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m            callbacks = [printLearningRate(),\n\u001b[1;32m     34\u001b[0m                         \u001b[0mprintLossesCallback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                         accuracyMetricEpochEnd()])\n\u001b[0m",
      "\u001b[0;32m~/Documents/github/wtc_deeplearning/Deep_qa.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, num_iter, learning_rate, decay, batch_size, fits_per_iteration, save_plot, verbose, callbacks)\u001b[0m\n\u001b[1;32m    131\u001b[0m                        \u001b[0manswers_intseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                        answers_intseq2[train_indices]]\n\u001b[0;32m--> 133\u001b[0;31m             X_val = [explain_intseq[val_indices],\n\u001b[0m\u001b[1;32m    134\u001b[0m                      \u001b[0mquestions_intseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                      \u001b[0manswers_intseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow35/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow35/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow35/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2664\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2666\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2667\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2668\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow35/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m                                 session)\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow35/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir('/home/liyuan/Documents/github/wtc_deeplearning/')\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'        \n",
    "\n",
    "from Deep_qa import Deep_qa\n",
    "import models\n",
    "import models_char\n",
    "from callbacks import printWeightsEpoch, printWeightsBatch, printLosses, historyEveryBatch, printLearningRate\n",
    "from callbacks import accuracyMetricEpochEnd, accuracyMetricTrainEnd\n",
    "\n",
    "\n",
    "temp = Deep_qa()\n",
    "embedding_flag = 'char'\n",
    "temp.load_data('char')\n",
    "temp.load_model(models_char.char_embedding_model,\n",
    "                char_embed_flag = 'cnn',\n",
    "                units = 20,\n",
    "                units_char = 20,\n",
    "                threshold = 0.5,\n",
    "                embedding_dim = 15, \n",
    "                dropout_rate = 0.5,\n",
    "               fcounts = [10,10,10,10,10,10])\n",
    "temp.summary()\n",
    "printLossesCallback = printLosses(print_list = 0)\n",
    "\n",
    "temp.train(num_iter = 100,\n",
    "           fits_per_iteration = 5,\n",
    "           verbose = 1,\n",
    "           batch_size = 64,\n",
    "           learning_rate = 0.001,\n",
    "           decay = 1e-4,\n",
    "           callbacks = [printLearningRate(),\n",
    "                        printLossesCallback,\n",
    "                        accuracyMetricEpochEnd()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1363/1363 [==============================] - 20s 15ms/step\n",
      "150/150 [==============================] - 2s 12ms/step\n",
      "150/150 [==============================] - 2s 15ms/step\n",
      "train,val,test accuracies: 0.53/0.31/0.41\n",
      "saved figure to ./images/char(char_embedding_model)_20(20)units_0.5thres_0.463loss_0.53_0.31_0.41acc.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved object to /pickled ...\n"
     ]
    }
   ],
   "source": [
    "temp.predict(subset = 0)\n",
    "temp.plot_losses(save_plot = 1)\n",
    "temp.save_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.train(num_iter = 55,\n",
    "           fits_per_iteration = 5,\n",
    "           verbose = 1,\n",
    "           batch_size = 64,\n",
    "           learning_rate = 0.00067,\n",
    "           decay = 1e-4,\n",
    "           callbacks = [printLearningRate(),\n",
    "                        printLossesCallback,\n",
    "                        accuracyMetricEpochEnd()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.predict(subset = 0)\n",
    "temp.plot_losses(save_plot = 1)\n",
    "temp.save_obj()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
